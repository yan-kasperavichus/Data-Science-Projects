{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c50c825e",
   "metadata": {},
   "source": [
    "Сверточные нейронные сети извлекают данные из изображение по кускам. Чем больше будет инпут лэйеров, тем более тщательно будет происходить процедура считывания. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdce0e4",
   "metadata": {},
   "source": [
    "1) Поступают данные на вход\n",
    "\n",
    "\n",
    "2) Процесс \"свертывания\" - грубо говоря здесь происходит создание признаков\n",
    "\n",
    "\n",
    "3) Объединение\n",
    "\n",
    "\n",
    "3.5) Каждый раз, когда нейросеть свертывает и объединяет данные, то создается hidden layer (скрытый слой)\n",
    "\n",
    "\n",
    "4) Один раз создается Fully Connected Layer (Полностью связаный слой), который по сути также является скрытым слоем и представляет из себя обычный слой нейронной сети\n",
    "\n",
    "\n",
    "5) Выходные данные"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d16220c",
   "metadata": {},
   "source": [
    "Поговорим о том, что такое \"свертывание\". Свертывание делит изображение, которое поступает на вход в сеть. Изображение делится на несколько окон. К примеру, 5 на 5. Внутри этих пяти оконо мы берем только 3-на-3 окон пространство, которое называется \"клетка\" В этом пространстве модель ищет признаки, которые помогут классифицировать изображение или дать окну \"название\". Далее мы перемещаем клетку, к примеру на 2 окна и у нас появляется новая клетка. Таким образом мы можем получить 4 клетки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3022dd15",
   "metadata": {},
   "source": [
    "Перейдем к \"объединению\". Мы получили 4 клетки. Каждая клетка может иметь какое-то значение внутри. К примеру мы получили такое же пространство из клеток 5-на-5, в каждом единичное окне лежат данные, которые мы получили на выходе из свертывания. Процесс объединение происходит точно также, как и свертывание, но разница в том, что при свертывании мы создавала признаки, а при объединении мы упрощаем выходные данные из свертывания. В матрице 5-на-5 мы снова берем клетку 3-на-3 единичных окон. Ищем самое большое значение внутри 3-на-3 клетки, среди единичных клеток и таким образом мы получаем новую клетку. Так мы получим снова 4 клетки, если будем перемещать на 2 единичных клетки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2bdbac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, LSTM\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "#physd = tf.config.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(physd[0], True)\n",
    "\n",
    "\n",
    "X = pickle.load(open('X.pickle', 'rb'))\n",
    "y = pickle.load(open('y.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f79b4f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#не дает модели использовать более 0.333 оперативки, помогает если надо обучать несколько моделей сразу (к примеру, когда\n",
    "#мы учили несколько моделей сразу играть в игру)\n",
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.99)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1108d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = 'Cats-vs-dog-cnn-64x2-{}'.format(int(time.time())) #изменим имя модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8376516c",
   "metadata": {},
   "source": [
    "Далее нужно нормализировать данные перед тем как они пройдут через нейронную сеть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ff91622",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4b760d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1:] #70 листов по 70 элементов в каждом - размер изображения, 1 - цвета"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45ed7f6",
   "metadata": {},
   "source": [
    "Анализ модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecf66b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "#После вызовам модели с этим параметром у нас появится папка в папке, где хранится проект"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b543fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "546/546 [==============================] - 11s 19ms/step - loss: 0.6229 - accuracy: 0.6474 - val_loss: 0.5940 - val_accuracy: 0.6754\n",
      "Epoch 2/10\n",
      "546/546 [==============================] - 10s 19ms/step - loss: 0.5203 - accuracy: 0.7436 - val_loss: 0.4982 - val_accuracy: 0.7592\n",
      "Epoch 3/10\n",
      "546/546 [==============================] - 10s 19ms/step - loss: 0.4667 - accuracy: 0.7786 - val_loss: 0.5188 - val_accuracy: 0.7547\n",
      "Epoch 4/10\n",
      "546/546 [==============================] - 10s 19ms/step - loss: 0.4244 - accuracy: 0.8093 - val_loss: 0.4663 - val_accuracy: 0.7790\n",
      "Epoch 5/10\n",
      "546/546 [==============================] - 10s 19ms/step - loss: 0.3761 - accuracy: 0.8298 - val_loss: 0.4606 - val_accuracy: 0.7896\n",
      "Epoch 6/10\n",
      "546/546 [==============================] - 10s 19ms/step - loss: 0.3286 - accuracy: 0.8570 - val_loss: 0.4651 - val_accuracy: 0.7827\n",
      "Epoch 7/10\n",
      "546/546 [==============================] - 10s 19ms/step - loss: 0.2800 - accuracy: 0.8805 - val_loss: 0.4819 - val_accuracy: 0.7851\n",
      "Epoch 8/10\n",
      "546/546 [==============================] - 10s 19ms/step - loss: 0.2248 - accuracy: 0.9083 - val_loss: 0.5386 - val_accuracy: 0.7845\n",
      "Epoch 9/10\n",
      "546/546 [==============================] - 10s 19ms/step - loss: 0.1710 - accuracy: 0.9323 - val_loss: 0.5661 - val_accuracy: 0.7818\n",
      "Epoch 10/10\n",
      "546/546 [==============================] - 10s 19ms/step - loss: 0.1242 - accuracy: 0.9536 - val_loss: 0.6571 - val_accuracy: 0.7822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1447dffec70>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3,3), input_shape=X.shape[1:])) #добавляем слой сверточной сети \n",
    "# (3,3) - размер окна, input_shape - сообщаем о форме входных данных, мы могли бы просто написать (50, 50, 1)\n",
    "#Conv всегда идет с Pooling, но можно после Conv сделать и активацию\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) #pool_size - размер окна, состоящего из 4 клеток, которые мы получили на выходе из\n",
    "#свертывания\n",
    "\n",
    "model.add(Conv2D(64, (3,3))) #добавляем слой сверточной сети\n",
    "#Conv всегда идет с Pooling, но можно после Conv сделать и активацию\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Теперь нужно сделать данные плоскими, т.к. сверточная нейронная сеть на выходе должна получать плоские данные (в 2D)\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64)) #Мы можем и не добавлять этот слой, но для более хорошей работы лучше добавим\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1)) #На выходе должен быть 1D-array\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', #т.к. у нас только два класса \n",
    "             optimizer='adam', #всегда используем его\n",
    "             metrics=['accuracy']) \n",
    "\n",
    "model.fit(X, y, batch_size=32, epochs=10, validation_split=0.3, callbacks=[tensorboard])\n",
    "#callbacks - это лист в котором находятся моменты обучения модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bef392b",
   "metadata": {},
   "source": [
    "# Анализ модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3954ab",
   "metadata": {},
   "source": [
    "Либо ты можешь зайти anaconda3, там зайти в environment, там запустить tensorflow с помощью terminal дальше переходить в свою папку:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd8519f",
   "metadata": {},
   "source": [
    "cd C:\\Users\\yanka\\Project\\\\\"Depp Learning Basics with Tensowr Flow and Keras\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39332303",
   "metadata": {},
   "source": [
    "Дальше вводишь"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd2f525",
   "metadata": {},
   "source": [
    "tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a106a6",
   "metadata": {},
   "source": [
    "Далее появится ссылка на дашборд, вставляешь её в браузер и все"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7ec035",
   "metadata": {},
   "source": [
    "Для удобства просмотра используем \\w в поиске"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d21f463",
   "metadata": {},
   "source": [
    "Здесь нужно в основном смотреть на то, как ведет себя val_loss. Даже если val_accuracy увеличивается, а val_loss возрастает снова в какой-то точке, то если мы добавим больше эпох, то в опр. момент acc начнет уменьшаться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "244093ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 - conv, 32 - nodes, 0 - dense - 1659028751\n",
      "\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 6s 8ms/step - loss: 0.6184 - accuracy: 0.6602 - val_loss: 0.5811 - val_accuracy: 0.7038\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 6s 8ms/step - loss: 0.5499 - accuracy: 0.7249 - val_loss: 0.5579 - val_accuracy: 0.7218\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 6s 8ms/step - loss: 0.5194 - accuracy: 0.7496 - val_loss: 0.5545 - val_accuracy: 0.7114\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 6s 8ms/step - loss: 0.4970 - accuracy: 0.7630 - val_loss: 0.5367 - val_accuracy: 0.7347\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 6s 8ms/step - loss: 0.4812 - accuracy: 0.7765 - val_loss: 0.5270 - val_accuracy: 0.7447\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 6s 8ms/step - loss: 0.4726 - accuracy: 0.7780 - val_loss: 0.5279 - val_accuracy: 0.7403\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 6s 8ms/step - loss: 0.4564 - accuracy: 0.7897 - val_loss: 0.5351 - val_accuracy: 0.7439\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 5s 8ms/step - loss: 0.4517 - accuracy: 0.7917 - val_loss: 0.5330 - val_accuracy: 0.7399\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 6s 8ms/step - loss: 0.4390 - accuracy: 0.7996 - val_loss: 0.5309 - val_accuracy: 0.7459\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 6s 8ms/step - loss: 0.4311 - accuracy: 0.8017 - val_loss: 0.5349 - val_accuracy: 0.7467\n",
      "\n",
      "2 - conv, 32 - nodes, 0 - dense - 1659028809\n",
      "\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 8s 10ms/step - loss: 0.6197 - accuracy: 0.6496 - val_loss: 0.5809 - val_accuracy: 0.6802\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 7s 9ms/step - loss: 0.5208 - accuracy: 0.7444 - val_loss: 0.5215 - val_accuracy: 0.7395\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 7s 9ms/step - loss: 0.4893 - accuracy: 0.7659 - val_loss: 0.5055 - val_accuracy: 0.7535\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 7s 9ms/step - loss: 0.4706 - accuracy: 0.7795 - val_loss: 0.4873 - val_accuracy: 0.7603\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 7s 9ms/step - loss: 0.4566 - accuracy: 0.7893 - val_loss: 0.4779 - val_accuracy: 0.7651\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 7s 9ms/step - loss: 0.4407 - accuracy: 0.7983 - val_loss: 0.4768 - val_accuracy: 0.7739\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 7s 9ms/step - loss: 0.4268 - accuracy: 0.8063 - val_loss: 0.4737 - val_accuracy: 0.7768\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 7s 9ms/step - loss: 0.4166 - accuracy: 0.8091 - val_loss: 0.4682 - val_accuracy: 0.7719\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 7s 9ms/step - loss: 0.4017 - accuracy: 0.8227 - val_loss: 0.4688 - val_accuracy: 0.7804\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 7s 10ms/step - loss: 0.3919 - accuracy: 0.8246 - val_loss: 0.4649 - val_accuracy: 0.7743\n",
      "\n",
      "3 - conv, 32 - nodes, 0 - dense - 1659028877\n",
      "\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 8s 10ms/step - loss: 0.6499 - accuracy: 0.6089 - val_loss: 0.6087 - val_accuracy: 0.6661\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 7s 10ms/step - loss: 0.5545 - accuracy: 0.7177 - val_loss: 0.5171 - val_accuracy: 0.7411\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 7s 10ms/step - loss: 0.5037 - accuracy: 0.7545 - val_loss: 0.5297 - val_accuracy: 0.7379\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 7s 10ms/step - loss: 0.4745 - accuracy: 0.7757 - val_loss: 0.4759 - val_accuracy: 0.7715\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 7s 10ms/step - loss: 0.4514 - accuracy: 0.7878 - val_loss: 0.4845 - val_accuracy: 0.7583\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 7s 10ms/step - loss: 0.4323 - accuracy: 0.8004 - val_loss: 0.4529 - val_accuracy: 0.7860\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 7s 10ms/step - loss: 0.4095 - accuracy: 0.8144 - val_loss: 0.4462 - val_accuracy: 0.7832\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 7s 10ms/step - loss: 0.3964 - accuracy: 0.8206 - val_loss: 0.4541 - val_accuracy: 0.7832\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 7s 10ms/step - loss: 0.3792 - accuracy: 0.8284 - val_loss: 0.4444 - val_accuracy: 0.7876\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 7s 10ms/step - loss: 0.3613 - accuracy: 0.8385 - val_loss: 0.4117 - val_accuracy: 0.8056\n",
      "\n",
      "1 - conv, 64 - nodes, 0 - dense - 1659028949\n",
      "\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 9s 12ms/step - loss: 0.6150 - accuracy: 0.6647 - val_loss: 0.5591 - val_accuracy: 0.7166\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 9s 12ms/step - loss: 0.5380 - accuracy: 0.7349 - val_loss: 0.5561 - val_accuracy: 0.7154\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 9s 12ms/step - loss: 0.5043 - accuracy: 0.7588 - val_loss: 0.5396 - val_accuracy: 0.7383\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 9s 12ms/step - loss: 0.4863 - accuracy: 0.7696 - val_loss: 0.5276 - val_accuracy: 0.7391\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 9s 12ms/step - loss: 0.4629 - accuracy: 0.7836 - val_loss: 0.5384 - val_accuracy: 0.7319\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 9s 12ms/step - loss: 0.4448 - accuracy: 0.7939 - val_loss: 0.5540 - val_accuracy: 0.7311\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 8s 12ms/step - loss: 0.4295 - accuracy: 0.8038 - val_loss: 0.5323 - val_accuracy: 0.7355\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 9s 12ms/step - loss: 0.4143 - accuracy: 0.8118 - val_loss: 0.5315 - val_accuracy: 0.7443\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 8s 12ms/step - loss: 0.4038 - accuracy: 0.8178 - val_loss: 0.5680 - val_accuracy: 0.7307\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 9s 13ms/step - loss: 0.3886 - accuracy: 0.8222 - val_loss: 0.5521 - val_accuracy: 0.7335\n",
      "\n",
      "2 - conv, 64 - nodes, 0 - dense - 1659029036\n",
      "\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 12s 17ms/step - loss: 0.6239 - accuracy: 0.6451 - val_loss: 0.5670 - val_accuracy: 0.7102\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 11s 16ms/step - loss: 0.5268 - accuracy: 0.7379 - val_loss: 0.5132 - val_accuracy: 0.7335\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 11s 16ms/step - loss: 0.4849 - accuracy: 0.7710 - val_loss: 0.5058 - val_accuracy: 0.7531\n",
      "Epoch 4/10\n",
      "364/702 [==============>...............] - ETA: 5s - loss: 0.4642 - accuracy: 0.7830"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Activation(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     45\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m#т.к. у нас только два класса \u001b[39;00m\n\u001b[0;32m     46\u001b[0m              optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m#всегда используем его\u001b[39;00m\n\u001b[0;32m     47\u001b[0m              metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]) \n\u001b[1;32m---> 49\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtensorboard\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\engine\\training.py:1414\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1412\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[0;32m   1413\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1414\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1416\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \n\u001b[0;32m    433\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 438\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    295\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 297\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    300\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    316\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 318\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    321\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    355\u001b[0m   hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 356\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    359\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1034\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\callbacks.py:1106\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1102\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1105\u001b[0m   \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1106\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1107\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\utils\\tf_utils.py:607\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[0;32m    605\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m--> 607\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:916\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    912\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    913\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    915\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 916\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    917\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:916\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    912\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    913\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    915\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 916\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    917\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\utils\\tf_utils.py:601\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    599\u001b[0m   \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    600\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 601\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    602\u001b[0m   \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[0;32m    603\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1159\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \n\u001b[0;32m   1138\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1159\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1125\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1126\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Здесь мы будем перебирать параметры. Лучше начинать с самых основных. Находим параметры, которые реально учат модель и от них\n",
    "#отталкиваемся. \n",
    "\n",
    "dense_layers = [0, 1, 2]\n",
    "layer_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2, 3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            #имя модели с параметрами и время её создания (чтобы запомнить)\n",
    "            MODEL_NAME = '{} - conv, {} - nodes, {} - dense - {}'.format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            tensorboard = TensorBoard(log_dir='/logs'.format(MODEL_NAME))\n",
    "            print()\n",
    "            print(MODEL_NAME)\n",
    "            print()\n",
    "            \n",
    "            model = Sequential()\n",
    "            model.add(Conv2D(layer_size, (3,3), input_shape=X.shape[1:])) #добавляем слой сверточной сети,\n",
    "            #первый слой должен иметь input_shape\n",
    "            # (3,3) - размер окна (не знаю что это, но вроде kernel size) \n",
    "            #Conv всегда идет с Pooling, но можно после Conv сделать и активацию\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "            for l in range(conv_layer-1): #-1, потому что у нас уже есть один conv_layer сверху на инпуте. Добавим переменную conv\n",
    "                model.add(Conv2D(layer_size, (3,3))) #добавляем слой сверточной сети, добавляем переменную в слой\n",
    "                # (3,3) - размер окна (не знаю что это)\n",
    "                #Conv всегда идет с Pooling, но можно после Conv сделать и активацию\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "                \n",
    "            #Теперь нужно сделать данные плоскими, т.к. сверточная нейронная сеть на выходе должна получать \n",
    "            #перый Dense должен иметь перед собой Flatten\n",
    "            model.add(Flatten())\n",
    "            \n",
    "            for l in range(dense_layer):\n",
    "                model.add(Dense(layer_size)) #помещаем переменную из цикла для перебора \n",
    "                model.add(Activation('relu'))\n",
    "\n",
    "            model.add(Dense(1)) #На выходе должен быть 1D-array, видимо\n",
    "\n",
    "            model.add(Activation('sigmoid'))\n",
    "            \n",
    "            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "            model.compile(loss='binary_crossentropy', #т.к. у нас только два класса \n",
    "                         optimizer='adam', #всегда используем его\n",
    "                         metrics=['accuracy']) \n",
    "\n",
    "            model.fit(X, y, batch_size=32, epochs=10, validation_split=0.1, callbacks =[tensorboard])\n",
    "            #callbacks - это лист в котором находятся моменты обучения модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abb2355",
   "metadata": {},
   "source": [
    "**Для этой модели logs хранятся в папке C:\\**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879d73d0",
   "metadata": {},
   "source": [
    "Дальше мы смотрим на графики. Из графика мы поняли, что с задачей лучше справляются модели с 0 dense_layers и 3 conv_layers. Поэтому, мы обновляем листы и оставляем 0 dense_layer, и 3 conv, а также делаем 64 нейрона (просто так). И убираем в цикле dense_layer переменную и вместо нее вставляем 512 (в данном случае так будет лучше)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8523653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 - conv, 64 - nodes, 0 - dense - 1659023576\n",
      "\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 13s 18ms/step - loss: 0.6070 - accuracy: 0.6635 - val_loss: 0.5355 - val_accuracy: 0.7255\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 11s 16ms/step - loss: 0.5159 - accuracy: 0.7497 - val_loss: 0.5003 - val_accuracy: 0.7475\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 17s 24ms/step - loss: 0.4766 - accuracy: 0.7755 - val_loss: 0.5141 - val_accuracy: 0.7379\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 11s 16ms/step - loss: 0.4477 - accuracy: 0.7929 - val_loss: 0.4671 - val_accuracy: 0.7756\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 11s 15ms/step - loss: 0.4250 - accuracy: 0.8064 - val_loss: 0.4562 - val_accuracy: 0.7892\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 11s 15ms/step - loss: 0.4045 - accuracy: 0.8201 - val_loss: 0.4554 - val_accuracy: 0.7820\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 11s 15ms/step - loss: 0.3843 - accuracy: 0.8279 - val_loss: 0.4367 - val_accuracy: 0.8036\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 11s 15ms/step - loss: 0.3607 - accuracy: 0.8408 - val_loss: 0.4296 - val_accuracy: 0.8052\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 11s 15ms/step - loss: 0.3486 - accuracy: 0.8463 - val_loss: 0.4415 - val_accuracy: 0.7944\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 11s 15ms/step - loss: 0.3263 - accuracy: 0.8609 - val_loss: 0.4322 - val_accuracy: 0.8036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 64x3-CNN.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 64x3-CNN.model\\assets\n"
     ]
    }
   ],
   "source": [
    "#Здесь мы будем перебирать параметры. Лучше начинать с самых основных. Находим параметры, которые реально учат модель и от них\n",
    "#отталкиваемся. \n",
    "\n",
    "dense_layers = [0]\n",
    "layer_sizes = [64]\n",
    "conv_layers = [2]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            #имя модели с параметрами и время её создания (чтобы запомнить)\n",
    "            MODEL_NAME = '{} - conv, {} - nodes, {} - dense - {}'.format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            tensorboard = TensorBoard(log_dir='/logs'.format(MODEL_NAME))\n",
    "            print(MODEL_NAME)\n",
    "            print()\n",
    "            \n",
    "            model = Sequential()\n",
    "            model.add(Conv2D(layer_size, (3,3), input_shape=X.shape[1:])) #добавляем слой сверточной сети,\n",
    "            #первый слой должен иметь input_shape\n",
    "            # (3,3) - размер окна (не знаю что это, но вроде kernel size) \n",
    "            #Conv всегда идет с Pooling, но можно после Conv сделать и активацию\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "            for l in range(conv_layer-1): #-1, потому что у нас уже есть один conv_layer сверху на инпуте. Добавим переменную conv\n",
    "                model.add(Conv2D(layer_size, (3,3))) #добавляем слой сверточной сети, добавляем переменную в слой\n",
    "                # (3,3) - размер окна (не знаю что это)\n",
    "                #Conv всегда идет с Pooling, но можно после Conv сделать и активацию\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "                \n",
    "            #Теперь нужно сделать данные плоскими, т.к. сверточная нейронная сеть на выходе должна получать \n",
    "            #перый Dense должен иметь перед собой Flatten\n",
    "            model.add(Flatten())\n",
    "            \n",
    "            for l in range(dense_layer):\n",
    "                model.add(Dense(layer_size)) #помещаем переменную из цикла для перебора \n",
    "                model.add(Activation('relu'))\n",
    "\n",
    "            model.add(Dense(1)) #На выходе должен быть 1D-array, видимо\n",
    "\n",
    "            model.add(Activation('sigmoid'))\n",
    "            \n",
    "            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "            model.compile(loss='binary_crossentropy', #т.к. у нас только два класса \n",
    "                         optimizer='adam', #всегда используем его\n",
    "                         metrics=['accuracy']) \n",
    "\n",
    "            model.fit(X, y, batch_size=32, epochs=10, validation_split=0.1, callbacks =[tensorboard])\n",
    "            #callbacks - это лист в котором находятся моменты обучения модели\n",
    "            \n",
    "model.save('64x3-CNN.model') #сохраняем модель (сохраняем весы и байес)         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e7b8b4",
   "metadata": {},
   "source": [
    "Даннаяя модель начинает переучиваться, если дать ей dense_layer. Это из-за того что у нас задача бинарной классификации, однако, если бы у нас была мильтиклассификация к примеру из датасета MNIST_Fashion, то нам нужна была бы более сложная модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f544ad03",
   "metadata": {},
   "source": [
    "Чтобы загрузить модель мы можем использовать "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbcf98c",
   "metadata": {},
   "source": [
    "Сначала обработаем изображение так, как был обработан остальной датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de50e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(filepath):\n",
    "    IMG_SIZE = 70\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d111dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('64x3-CNN.model') #загружаем модель\n",
    "\n",
    "prediction = model.predict([prepare('dog.jpg')]) #делаем предсказание, обработав сэмпл\n",
    "\n",
    "print(CATEGORIES[int(prediction[0][0])])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.4",
   "language": "python",
   "name": "tf2.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
